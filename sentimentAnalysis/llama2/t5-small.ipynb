{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83bad2b9-1e39-4213-8ce9-d116e29141bf",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/lucamassaron/fine-tune-llama-2-for-sentiment-analysis\n",
    "\n",
    "https://davidanifowoshe.medium.com/fine-tuning-roberta-for-covid-19-tweet-sentiment-classification-4063b85ff2e3\n",
    "\n",
    "https://github.com/DeeeTeeee/FineTuningSentimentAnalysis/blob/master/src/Fine_tuning_Hugging_face_trainer_roberta.ipynb\n",
    "\n",
    "https://www.kaggle.com/code/evilmage93/t5-finetuning-on-sentiment-classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7eea940-c7a6-42e5-9f41-051f1c638f82",
   "metadata": {},
   "source": [
    "input_ids and attention_mask represent tokenized text and control flags, not numerical features with meaningful distances. Since SMOTE requires numerical features for creating synthetic samples through interpolation, directly using these tokenized texts and masks is not feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6394d4a9-52bb-4e89-8d4e-ec4aca0f5d83",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c71abd73-68b9-4b4d-beb0-799c20f3fe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, default_data_collator, EarlyStoppingCallback, IntervalStrategy\n",
    "#from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score # Import all needed metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "706328c1-b18e-4b66-aecb-460a81d69ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42c1c3df-fa97-4476-94fe-323a0e835b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/home/patrick.araujo/llama2/datasets/balanced_output_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cca0584e-794c-4412-87f6-a913d976dd5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviewId</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lengthContent</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1007</td>\n",
       "      <td>1527</td>\n",
       "      <td>1527</td>\n",
       "      <td>7d6a4b7f-0f17-47c6-8010-3187dd1c86a7</td>\n",
       "      <td>I've been using my visa gift card. All the inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26.23.4.100</td>\n",
       "      <td>2023-12-28 21:20:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.23.4.100</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8622</td>\n",
       "      <td>12941</td>\n",
       "      <td>12941</td>\n",
       "      <td>227c23e5-e178-4d69-bb99-3fe1445dc035</td>\n",
       "      <td>the PRIME PRICE IS WAY TO HIGH!!</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>26.19.2.100</td>\n",
       "      <td>2023-10-02 12:09:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.19.2.100</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7774</td>\n",
       "      <td>11420</td>\n",
       "      <td>11420</td>\n",
       "      <td>bc748a49-bbd9-4773-a63f-f0950ad66310</td>\n",
       "      <td>easy to use and fast free delivery</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>26.20.0.100</td>\n",
       "      <td>2023-10-25 03:46:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.20.0.100</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5478</td>\n",
       "      <td>8135</td>\n",
       "      <td>8135</td>\n",
       "      <td>0b2c1d90-3026-427a-bea9-918d1e067e8f</td>\n",
       "      <td>The Shopping On Amazon Is The Greatest Of All....</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-12 01:54:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>111</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13393</td>\n",
       "      <td>19072</td>\n",
       "      <td>19072</td>\n",
       "      <td>bee9613a-352d-4328-abaa-986316fe788d</td>\n",
       "      <td>I am rarely not satisfied seems I'm always sat...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>24.22.0.100</td>\n",
       "      <td>2023-01-10 09:30:07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.22.0.100</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9307</th>\n",
       "      <td>7444</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>e95c926d-6510-4b97-8ad7-7b11885a46a7</td>\n",
       "      <td>Amazon is always my go to for everything!!</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>26.21.0.100</td>\n",
       "      <td>2023-11-03 01:06:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.21.0.100</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9308</th>\n",
       "      <td>17040</td>\n",
       "      <td>24320</td>\n",
       "      <td>24320</td>\n",
       "      <td>f26c2ae2-6868-49ab-9845-963ce24f14f8</td>\n",
       "      <td>This is a great app but I didn't get my neckla...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.14.0.100</td>\n",
       "      <td>2022-06-01 13:35:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.14.0.100</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9309</th>\n",
       "      <td>14542</td>\n",
       "      <td>20557</td>\n",
       "      <td>20557</td>\n",
       "      <td>cd102f54-3164-494c-8287-b2064c82401b</td>\n",
       "      <td>11-3-22- I have 107 S&amp;S items. It is impossibl...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>24.20.2.100</td>\n",
       "      <td>2022-11-03 11:59:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.20.2.100</td>\n",
       "      <td>2</td>\n",
       "      <td>320</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310</th>\n",
       "      <td>16186</td>\n",
       "      <td>22964</td>\n",
       "      <td>22964</td>\n",
       "      <td>d8372268-d77e-4666-a2dd-166decb97443</td>\n",
       "      <td>App sucks! Glitchy, slow, hurts my eyes cuz im...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24.12.6.100</td>\n",
       "      <td>2022-07-21 14:35:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.12.6.100</td>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9311</th>\n",
       "      <td>3005</td>\n",
       "      <td>4351</td>\n",
       "      <td>4351</td>\n",
       "      <td>b4800993-d2c7-4f29-9b36-6b758e882a94</td>\n",
       "      <td>Look this app was good at one point in time bu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.22.0.100</td>\n",
       "      <td>2023-12-07 13:47:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.22.0.100</td>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9312 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      level_0  index  Unnamed: 0                              reviewId  \\\n",
       "0        1007   1527        1527  7d6a4b7f-0f17-47c6-8010-3187dd1c86a7   \n",
       "1        8622  12941       12941  227c23e5-e178-4d69-bb99-3fe1445dc035   \n",
       "2        7774  11420       11420  bc748a49-bbd9-4773-a63f-f0950ad66310   \n",
       "3        5478   8135        8135  0b2c1d90-3026-427a-bea9-918d1e067e8f   \n",
       "4       13393  19072       19072  bee9613a-352d-4328-abaa-986316fe788d   \n",
       "...       ...    ...         ...                                   ...   \n",
       "9307     7444  10822       10822  e95c926d-6510-4b97-8ad7-7b11885a46a7   \n",
       "9308    17040  24320       24320  f26c2ae2-6868-49ab-9845-963ce24f14f8   \n",
       "9309    14542  20557       20557  cd102f54-3164-494c-8287-b2064c82401b   \n",
       "9310    16186  22964       22964  d8372268-d77e-4666-a2dd-166decb97443   \n",
       "9311     3005   4351        4351  b4800993-d2c7-4f29-9b36-6b758e882a94   \n",
       "\n",
       "                                                content  score  thumbsUpCount  \\\n",
       "0     I've been using my visa gift card. All the inf...      1              2   \n",
       "1                      the PRIME PRICE IS WAY TO HIGH!!      5              0   \n",
       "2                    easy to use and fast free delivery      5              0   \n",
       "3     The Shopping On Amazon Is The Greatest Of All....      5              0   \n",
       "4     I am rarely not satisfied seems I'm always sat...      4              0   \n",
       "...                                                 ...    ...            ...   \n",
       "9307         Amazon is always my go to for everything!!      5              0   \n",
       "9308  This is a great app but I didn't get my neckla...      3              1   \n",
       "9309  11-3-22- I have 107 S&S items. It is impossibl...      4              9   \n",
       "9310  App sucks! Glitchy, slow, hurts my eyes cuz im...      3              0   \n",
       "9311  Look this app was good at one point in time bu...      1              0   \n",
       "\n",
       "     reviewCreatedVersion                   at  replyContent  repliedAt  \\\n",
       "0             26.23.4.100  2023-12-28 21:20:56           NaN        NaN   \n",
       "1             26.19.2.100  2023-10-02 12:09:02           NaN        NaN   \n",
       "2             26.20.0.100  2023-10-25 03:46:34           NaN        NaN   \n",
       "3                     NaN  2023-11-12 01:54:20           NaN        NaN   \n",
       "4             24.22.0.100  2023-01-10 09:30:07           NaN        NaN   \n",
       "...                   ...                  ...           ...        ...   \n",
       "9307          26.21.0.100  2023-11-03 01:06:14           NaN        NaN   \n",
       "9308          22.14.0.100  2022-06-01 13:35:57           NaN        NaN   \n",
       "9309          24.20.2.100  2022-11-03 11:59:23           NaN        NaN   \n",
       "9310          24.12.6.100  2022-07-21 14:35:03           NaN        NaN   \n",
       "9311          26.22.0.100  2023-12-07 13:47:06           NaN        NaN   \n",
       "\n",
       "       appVersion  sentiment  lengthContent Language  \n",
       "0     26.23.4.100          0            224       en  \n",
       "1     26.19.2.100          2             32       en  \n",
       "2     26.20.0.100          2             34       en  \n",
       "3             NaN          2            111       en  \n",
       "4     24.22.0.100          2             64       en  \n",
       "...           ...        ...            ...      ...  \n",
       "9307  26.21.0.100          2             42       en  \n",
       "9308  22.14.0.100          1            240       en  \n",
       "9309  24.20.2.100          2            320       en  \n",
       "9310  24.12.6.100          1            231       en  \n",
       "9311  26.22.0.100          0            380       en  \n",
       "\n",
       "[9312 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "228145a7-7564-4916-810b-a8b33d4cfa67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9312, 15)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf493e34-b234-4292-8f65-4840ad1966e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "0    3104\n",
      "1    3104\n",
      "2    3104\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sentiment_counts_balanced = dataset['sentiment'].value_counts().sort_index()\n",
    "print(sentiment_counts_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d20ed7-4173-441e-892e-ef2186d0c080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of T5ForSequenceClassification were not initialized from the model checkpoint at google-t5/t5-small and are newly initialized: ['classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.bias', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained BERT model and tokenizer\n",
    "#model_name = \"/home/patrick.araujo/llama2/llama/llama-2-7b-hf\"\n",
    "#model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "#model_name = \"bert-base-uncased\"\n",
    "#model_name = \"google-t5/t5-base\"\n",
    "model_name = \"google-t5/t5-small\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3, token=access_token)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ee838fb-4ff0-4b5a-abaa-5c7403e74232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and validation datasets\n",
    "comments = dataset[['content', 'sentiment']]\n",
    "train_data, val_data = train_test_split(comments, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f7ca671-8d21-4e12-969e-dbbb34b245bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>Usually love the app but lately if I try to us...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5813</th>\n",
       "      <td>It's okay sometimes if you really follow the s...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Here's to all the people that make all the goo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>It's amazing but some of the stuff I want isn'...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5057</th>\n",
       "      <td>How disgraceful all these complaints and still...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>No longer works with Tablets mine is a Samsung...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>Just wish we had more American Made products t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>Excellent customer service. So many choices! B...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Amazon prices aren't bad, they deliver fairly ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>Lowered stars for embedded autoplay videos</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7449 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  sentiment\n",
       "503   Usually love the app but lately if I try to us...          1\n",
       "5813  It's okay sometimes if you really follow the s...          2\n",
       "274   Here's to all the people that make all the goo...          2\n",
       "1345  It's amazing but some of the stuff I want isn'...          2\n",
       "5057  How disgraceful all these complaints and still...          0\n",
       "...                                                 ...        ...\n",
       "5734  No longer works with Tablets mine is a Samsung...          0\n",
       "5191  Just wish we had more American Made products t...          2\n",
       "5390  Excellent customer service. So many choices! B...          2\n",
       "860   Amazon prices aren't bad, they deliver fairly ...          2\n",
       "7270         Lowered stars for embedded autoplay videos          0\n",
       "\n",
       "[7449 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14ffdc28-d79b-4c2e-9bb1-6259d19c5ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8638</th>\n",
       "      <td>Amazon shopping app doesn't allow user to clea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Can't vote my orders. It just refreshes my ord...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>App is barely better than web experience, but ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>Wishlist scrolling doesn't work</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>With the problems of item deliveries thru USPS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6657</th>\n",
       "      <td>Have to watch an add before you can use the ap...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>App is not bad, but I used it mostly to track ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>I dispise that the app has injected a search i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603</th>\n",
       "      <td>I've officially deleted my account after using...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>Video ads chopping scrolling, this is no a fre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1863 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  sentiment\n",
       "8638  Amazon shopping app doesn't allow user to clea...          1\n",
       "131   Can't vote my orders. It just refreshes my ord...          1\n",
       "3509  App is barely better than web experience, but ...          2\n",
       "4401                    Wishlist scrolling doesn't work          0\n",
       "3095  With the problems of item deliveries thru USPS...          0\n",
       "...                                                 ...        ...\n",
       "6657  Have to watch an add before you can use the ap...          0\n",
       "4271  App is not bad, but I used it mostly to track ...          1\n",
       "2404  I dispise that the app has injected a search i...          0\n",
       "6603  I've officially deleted my account after using...          0\n",
       "2362  Video ads chopping scrolling, this is no a fre...          0\n",
       "\n",
       "[1863 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39cfbc34-fcb0-4c42-9329-cb48ec2a94e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.pad_token = tokenizer.eos_token\n",
    "#tokenizer.padding_size = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1ebd985-7161-4c19-95c9-dc3412ae658e",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512\n",
    "\n",
    "def tokenizerFunction(string):\n",
    "  # Tokenize a list of texts and return a dictionary with the tokenization outputs\n",
    "  tokens = tokenizer(string, padding='max_length', truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "  return tokens\n",
    "\n",
    "train_encodings = train_data['content'].apply(tokenizerFunction)\n",
    "val_encodings = val_data['content'].apply(tokenizerFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2248e82-fbba-4e88-9ed6-d0eafb4044d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503     [input_ids, attention_mask]\n",
       "5813    [input_ids, attention_mask]\n",
       "274     [input_ids, attention_mask]\n",
       "1345    [input_ids, attention_mask]\n",
       "5057    [input_ids, attention_mask]\n",
       "                   ...             \n",
       "5734    [input_ids, attention_mask]\n",
       "5191    [input_ids, attention_mask]\n",
       "5390    [input_ids, attention_mask]\n",
       "860     [input_ids, attention_mask]\n",
       "7270    [input_ids, attention_mask]\n",
       "Name: content, Length: 7449, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7ce24a7-cb34-4848-9f55-738a6fe9a732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8638    [input_ids, attention_mask]\n",
       "131     [input_ids, attention_mask]\n",
       "3509    [input_ids, attention_mask]\n",
       "4401    [input_ids, attention_mask]\n",
       "3095    [input_ids, attention_mask]\n",
       "                   ...             \n",
       "6657    [input_ids, attention_mask]\n",
       "4271    [input_ids, attention_mask]\n",
       "2404    [input_ids, attention_mask]\n",
       "6603    [input_ids, attention_mask]\n",
       "2362    [input_ids, attention_mask]\n",
       "Name: content, Length: 1863, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ea91f4d-7e44-4778-8499-04db37d43363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatingDataframe(encodings):\n",
    "  indices = encodings.index.to_numpy()\n",
    "\n",
    "  df = pd.DataFrame(columns=['input_ids', 'attention_mask'])\n",
    "  \n",
    "  # Assuming 'content' is a Series or List containing tuples/lists\n",
    "  for element in encodings:\n",
    "    input_ids = element['input_ids'][0].numpy()              # Replace with correct index based on your data structure\n",
    "    attention_mask = element['attention_mask'][0].numpy()    # Replace with correct index\n",
    "    df.loc[len(df.index)] = [input_ids, attention_mask]\n",
    "  df_index = pd.DataFrame(indices, columns=['index'])\n",
    "  df['index'] = df_index['index']\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ee5044d-33cf-4115-b3eb-38d0eceedd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "# Convert labels to tensors\n",
    "train_dataset = creatingDataframe(train_encodings)\n",
    "train_labels = train_data['sentiment'].reset_index(name='label')\n",
    "train_dataset = pd.merge(train_dataset, train_labels, on='index')\n",
    "\n",
    "val_dataset = creatingDataframe(val_encodings)\n",
    "val_labels = val_data['sentiment'].reset_index(name='label')\n",
    "val_dataset = pd.merge(val_dataset, val_labels, on='index')\n",
    "\n",
    "# Define batch size and create data loaders\n",
    "batch_size = 8  # Adjust as needed\n",
    "# train_dataset = SentimentDataset(train_encodings, train_labels)\n",
    "# val_dataset = SentimentDataset(val_encodings, val_labels)\n",
    "#train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=default_data_collator)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=default_data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7bcd6d00-18b6-499c-b101-86c481320638",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.drop('index', axis=1)\n",
    "val_dataset = val_dataset.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21aa430d-ab19-431a-9c76-499a457a014f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3, 12576, 333, 8, 1120, 68, 12643, 3, 99, 27,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[94, 31, 7, 8957, 1664, 3, 99, 25, 310, 1130, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[947, 31, 7, 12, 66, 8, 151, 24, 143, 66, 8, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[94, 31, 7, 1237, 68, 128, 13, 8, 2005, 27, 24...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[571, 1028, 122, 12614, 1329, 66, 175, 11244, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7444</th>\n",
       "      <td>[465, 1200, 930, 28, 14571, 7, 2000, 19, 3, 9,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7445</th>\n",
       "      <td>[1142, 1663, 62, 141, 72, 797, 6465, 494, 12, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7446</th>\n",
       "      <td>[11497, 884, 313, 5, 264, 186, 3703, 55, 1648,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7447</th>\n",
       "      <td>[2536, 1596, 33, 29, 31, 17, 1282, 6, 79, 2156...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7448</th>\n",
       "      <td>[5586, 3737, 4811, 21, 13612, 1510, 4895, 3075...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7449 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_ids  \\\n",
       "0     [3, 12576, 333, 8, 1120, 68, 12643, 3, 99, 27,...   \n",
       "1     [94, 31, 7, 8957, 1664, 3, 99, 25, 310, 1130, ...   \n",
       "2     [947, 31, 7, 12, 66, 8, 151, 24, 143, 66, 8, 2...   \n",
       "3     [94, 31, 7, 1237, 68, 128, 13, 8, 2005, 27, 24...   \n",
       "4     [571, 1028, 122, 12614, 1329, 66, 175, 11244, ...   \n",
       "...                                                 ...   \n",
       "7444  [465, 1200, 930, 28, 14571, 7, 2000, 19, 3, 9,...   \n",
       "7445  [1142, 1663, 62, 141, 72, 797, 6465, 494, 12, ...   \n",
       "7446  [11497, 884, 313, 5, 264, 186, 3703, 55, 1648,...   \n",
       "7447  [2536, 1596, 33, 29, 31, 17, 1282, 6, 79, 2156...   \n",
       "7448  [5586, 3737, 4811, 21, 13612, 1510, 4895, 3075...   \n",
       "\n",
       "                                         attention_mask  label  \n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      1  \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...      2  \n",
       "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      2  \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      2  \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \n",
       "...                                                 ...    ...  \n",
       "7444  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \n",
       "7445  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, ...      2  \n",
       "7446  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      2  \n",
       "7447  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      2  \n",
       "7448  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...      0  \n",
       "\n",
       "[7449 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ab6ab32-fbae-4a13-8430-82290d840fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[2536, 2309, 1120, 744, 31, 17, 995, 1139, 12,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1072, 31, 17, 2902, 82, 5022, 5, 94, 131, 162...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[2276, 19, 11289, 394, 145, 765, 351, 6, 68, 3...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[16675, 3350, 11930, 53, 744, 31, 17, 161, 1, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[438, 8, 982, 13, 2118, 23113, 20380, 837, 417...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>[2114, 12, 1605, 46, 617, 274, 25, 54, 169, 8,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>[2276, 19, 59, 1282, 6, 68, 27, 261, 34, 3323,...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>[27, 3, 10475, 159, 15, 24, 8, 1120, 65, 3, 26...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>[27, 31, 162, 8441, 16355, 82, 905, 227, 338, ...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>[3953, 6543, 3, 75, 21714, 11930, 53, 6, 48, 1...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1863 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_ids  \\\n",
       "0     [2536, 2309, 1120, 744, 31, 17, 995, 1139, 12,...   \n",
       "1     [1072, 31, 17, 2902, 82, 5022, 5, 94, 131, 162...   \n",
       "2     [2276, 19, 11289, 394, 145, 765, 351, 6, 68, 3...   \n",
       "3     [16675, 3350, 11930, 53, 744, 31, 17, 161, 1, ...   \n",
       "4     [438, 8, 982, 13, 2118, 23113, 20380, 837, 417...   \n",
       "...                                                 ...   \n",
       "1858  [2114, 12, 1605, 46, 617, 274, 25, 54, 169, 8,...   \n",
       "1859  [2276, 19, 59, 1282, 6, 68, 27, 261, 34, 3323,...   \n",
       "1860  [27, 3, 10475, 159, 15, 24, 8, 1120, 65, 3, 26...   \n",
       "1861  [27, 31, 162, 8441, 16355, 82, 905, 227, 338, ...   \n",
       "1862  [3953, 6543, 3, 75, 21714, 11930, 53, 6, 48, 1...   \n",
       "\n",
       "                                         attention_mask  label  \n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      1  \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      1  \n",
       "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      2  \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...      0  \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \n",
       "...                                                 ...    ...  \n",
       "1858  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \n",
       "1859  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      1  \n",
       "1860  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \n",
       "1861  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \n",
       "1862  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \n",
       "\n",
       "[1863 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f524955f-83f6-4aac-97c6-25f5952bf6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class\n",
    "#class CustomDataset(Dataset):\n",
    "#    def __init__(self, dataframe, data):\n",
    "#        self._data = data\n",
    "#\n",
    "#    def __len__(self):\n",
    "#        return len(self._data)\n",
    "#\n",
    "#    def __getitem__(self, idx):\n",
    "#        label = self.labels[idx]\n",
    "#        input_ids = self.input_ids[idx]\n",
    "#        attention_mask = self.attention_masks[idx]\n",
    "#        return {\n",
    "#            'input_ids': torch.tensor(dataframe['input_ids'], dtype=torch.long),\n",
    "#            'attention_mask': torch.tensor(dataframe['attention_mask'], dtype=torch.long),\n",
    "#            'labels': torch.tensor(dataframe['label'], dtype=torch.long)\n",
    "#        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a80ad4b2-8be0-4cba-89ff-4308a013ae14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = CustomDataset(train_dataset, train_data)\n",
    "#val_dataset = CustomDataset(val_dataset, val_data)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_dataset)\n",
    "val_dataset = Dataset.from_pandas(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c810114b-4bbb-4bb6-81ae-616e4141c89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments with early stopping\n",
    "training_args = TrainingArguments(\n",
    "    # Positional arguments:\n",
    "    output_dir=\"./t5-small_sentiment_model\",\n",
    "    logging_dir=\"./logs\",\n",
    "\n",
    "    # Keyword arguments:\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    #eval_steps=250,                         # Adjust as needed\n",
    "    #save_total_limit=2,                     # Adjust as needed. Only last 2 models are saved. Older ones are deleted.\n",
    "    num_train_epochs=10,                     # Adjust as needed\n",
    "    #save_steps=500,                         # Adjust as needed\n",
    "    metric_for_best_model=\"eval_loss\",      # Use validation loss for early stopping\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92a78045-f55e-4e41-94bf-82cfa5afcac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "\n",
    "    logits = eval_pred[0]\n",
    "    logits, labels = logits\n",
    "    \n",
    "    labels = eval_pred[1]\n",
    "    \n",
    "    # Convert logits to predicted labels\n",
    "    predicted_labels = np.argmax(logits, axis=1)\n",
    "\n",
    "    metrics = {}\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels, predicted_labels)\n",
    "    metrics['accuracy'] = accuracy\n",
    "\n",
    "    # Calculate precision, recall, F1 score, and support for each class\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(labels, predicted_labels)    \n",
    "    \n",
    "\n",
    "    # Create a dictionary to store metrics for each class\n",
    "    class_metrics = {}\n",
    "    for i in range(len(precision)):\n",
    "        class_metrics[f'class_{i}'] = {\n",
    "            'precision': precision[i],\n",
    "            'recall': recall[i],\n",
    "            'f1': f1[i],\n",
    "            'support': support[i]\n",
    "        }\n",
    "\n",
    "    precision_ALL = precision_score(labels, predicted_labels, average='macro')\n",
    "    recall_ALL = recall_score(labels, predicted_labels, average='macro')\n",
    "    f1_ALL = f1_score(labels, predicted_labels, average='macro')\n",
    "\n",
    "    metrics['precision'] = precision_ALL\n",
    "    metrics['recall'] = recall_ALL\n",
    "    metrics['f1'] = f1_ALL\n",
    "    \n",
    "    # Print and return the metrics\n",
    "    for class_name, c_metrics in class_metrics.items():\n",
    "        metrics[f'{class_name}_precision'] = c_metrics[\"precision\"]\n",
    "        metrics[f'{class_name}_recall'] = c_metrics[\"recall\"]\n",
    "        metrics[f'{class_name}_f1'] = c_metrics[\"f1\"]\n",
    "        metrics[f'{class_name}_support'] = c_metrics[\"support\"]\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62125982-7b3c-487c-9915-cce5bdc2354c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_metrics(eval_pred):\n",
    "    \n",
    "#     logits = eval_pred[0]\n",
    "#     logits, labels = logits\n",
    "    \n",
    "#     labels = eval_pred[1]\n",
    "    \n",
    "#     #print(\"imprimindo labels\")\n",
    "#     #print(labels)\n",
    "    \n",
    "#     # Proceed with metrics calculation\n",
    "#     predictions = np.argmax(logits, axis=1)\n",
    "\n",
    "    \n",
    "#     accuracy = accuracy_score(y_true=labels, y_pred=predictions)\n",
    "#     recall = recall_score(y_true=labels, y_pred=predictions, average='macro')\n",
    "#     precision = precision_score(y_true=labels, y_pred=predictions, average='macro')\n",
    "#     f1 = f1_score(y_true=labels, y_pred=predictions, average='macro')  # Add line for F1 score\n",
    "#     return {\n",
    "#         'accuracy': accuracy,\n",
    "#         'recall': recall,\n",
    "#         'precision': precision,\n",
    "#         'f1': f1  # Include F1 score in the dictionary\n",
    "#     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0439f608-9998-4f7a-889f-ede994203d0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Initialize the trainer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefault_data_collator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mEarlyStoppingCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/trainer.py:459\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mBITS_AND_BYTES\n\u001b[1;32m    458\u001b[0m ):\n\u001b[0;32m--> 459\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_move_model_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/trainer.py:693\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[0;34m(self, model, device)\u001b[0m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[0;32m--> 693\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    694\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[1;32m    695\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/modeling_utils.py:2595\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2590\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2591\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2592\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2593\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2594\u001b[0m         )\n\u001b[0;32m-> 2595\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: out of memory\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=default_data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640a88ab-0b45-49e1-baaf-729635c6dc60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8909445-c8f9-4b86-9870-e12043deacc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ab1836-a92d-47bc-b2c7-b192002f1872",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e83d7c0-f1a1-4342-ae35-a635b6bf68de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"./t5-small_sentiment_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
