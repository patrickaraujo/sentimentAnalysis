{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248cd625-f9ce-4024-815e-c9c37acd4432",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aea2fbc3-83d1-459d-8f37-58235c3e08cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, default_data_collator, EarlyStoppingCallback, IntervalStrategy\n",
    "#from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score # Import all needed metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ee773a17-6fc1-41f8-be09-c94910c20f2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "006f128c-51c1-440d-b859-a754b4e4761c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/home/patrick.araujo/llama2/datasets/balanced_output_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4408a86b-e1fc-483a-9e49-426772a5f61a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviewId</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>lengthContent</th>\n",
       "      <th>Language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1007</td>\n",
       "      <td>1527</td>\n",
       "      <td>1527</td>\n",
       "      <td>7d6a4b7f-0f17-47c6-8010-3187dd1c86a7</td>\n",
       "      <td>I've been using my visa gift card. All the inf...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>26.23.4.100</td>\n",
       "      <td>2023-12-28 21:20:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.23.4.100</td>\n",
       "      <td>0</td>\n",
       "      <td>224</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8622</td>\n",
       "      <td>12941</td>\n",
       "      <td>12941</td>\n",
       "      <td>227c23e5-e178-4d69-bb99-3fe1445dc035</td>\n",
       "      <td>the PRIME PRICE IS WAY TO HIGH!!</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>26.19.2.100</td>\n",
       "      <td>2023-10-02 12:09:02</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.19.2.100</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7774</td>\n",
       "      <td>11420</td>\n",
       "      <td>11420</td>\n",
       "      <td>bc748a49-bbd9-4773-a63f-f0950ad66310</td>\n",
       "      <td>easy to use and fast free delivery</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>26.20.0.100</td>\n",
       "      <td>2023-10-25 03:46:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.20.0.100</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5478</td>\n",
       "      <td>8135</td>\n",
       "      <td>8135</td>\n",
       "      <td>0b2c1d90-3026-427a-bea9-918d1e067e8f</td>\n",
       "      <td>The Shopping On Amazon Is The Greatest Of All....</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-11-12 01:54:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>111</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13393</td>\n",
       "      <td>19072</td>\n",
       "      <td>19072</td>\n",
       "      <td>bee9613a-352d-4328-abaa-986316fe788d</td>\n",
       "      <td>I am rarely not satisfied seems I'm always sat...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>24.22.0.100</td>\n",
       "      <td>2023-01-10 09:30:07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.22.0.100</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9307</th>\n",
       "      <td>7444</td>\n",
       "      <td>10822</td>\n",
       "      <td>10822</td>\n",
       "      <td>e95c926d-6510-4b97-8ad7-7b11885a46a7</td>\n",
       "      <td>Amazon is always my go to for everything!!</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>26.21.0.100</td>\n",
       "      <td>2023-11-03 01:06:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.21.0.100</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9308</th>\n",
       "      <td>17040</td>\n",
       "      <td>24320</td>\n",
       "      <td>24320</td>\n",
       "      <td>f26c2ae2-6868-49ab-9845-963ce24f14f8</td>\n",
       "      <td>This is a great app but I didn't get my neckla...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.14.0.100</td>\n",
       "      <td>2022-06-01 13:35:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.14.0.100</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9309</th>\n",
       "      <td>14542</td>\n",
       "      <td>20557</td>\n",
       "      <td>20557</td>\n",
       "      <td>cd102f54-3164-494c-8287-b2064c82401b</td>\n",
       "      <td>11-3-22- I have 107 S&amp;S items. It is impossibl...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>24.20.2.100</td>\n",
       "      <td>2022-11-03 11:59:23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.20.2.100</td>\n",
       "      <td>2</td>\n",
       "      <td>320</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9310</th>\n",
       "      <td>16186</td>\n",
       "      <td>22964</td>\n",
       "      <td>22964</td>\n",
       "      <td>d8372268-d77e-4666-a2dd-166decb97443</td>\n",
       "      <td>App sucks! Glitchy, slow, hurts my eyes cuz im...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>24.12.6.100</td>\n",
       "      <td>2022-07-21 14:35:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.12.6.100</td>\n",
       "      <td>1</td>\n",
       "      <td>231</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9311</th>\n",
       "      <td>3005</td>\n",
       "      <td>4351</td>\n",
       "      <td>4351</td>\n",
       "      <td>b4800993-d2c7-4f29-9b36-6b758e882a94</td>\n",
       "      <td>Look this app was good at one point in time bu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.22.0.100</td>\n",
       "      <td>2023-12-07 13:47:06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26.22.0.100</td>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9312 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      level_0  index  Unnamed: 0                              reviewId  \\\n",
       "0        1007   1527        1527  7d6a4b7f-0f17-47c6-8010-3187dd1c86a7   \n",
       "1        8622  12941       12941  227c23e5-e178-4d69-bb99-3fe1445dc035   \n",
       "2        7774  11420       11420  bc748a49-bbd9-4773-a63f-f0950ad66310   \n",
       "3        5478   8135        8135  0b2c1d90-3026-427a-bea9-918d1e067e8f   \n",
       "4       13393  19072       19072  bee9613a-352d-4328-abaa-986316fe788d   \n",
       "...       ...    ...         ...                                   ...   \n",
       "9307     7444  10822       10822  e95c926d-6510-4b97-8ad7-7b11885a46a7   \n",
       "9308    17040  24320       24320  f26c2ae2-6868-49ab-9845-963ce24f14f8   \n",
       "9309    14542  20557       20557  cd102f54-3164-494c-8287-b2064c82401b   \n",
       "9310    16186  22964       22964  d8372268-d77e-4666-a2dd-166decb97443   \n",
       "9311     3005   4351        4351  b4800993-d2c7-4f29-9b36-6b758e882a94   \n",
       "\n",
       "                                                content  score  thumbsUpCount  \\\n",
       "0     I've been using my visa gift card. All the inf...      1              2   \n",
       "1                      the PRIME PRICE IS WAY TO HIGH!!      5              0   \n",
       "2                    easy to use and fast free delivery      5              0   \n",
       "3     The Shopping On Amazon Is The Greatest Of All....      5              0   \n",
       "4     I am rarely not satisfied seems I'm always sat...      4              0   \n",
       "...                                                 ...    ...            ...   \n",
       "9307         Amazon is always my go to for everything!!      5              0   \n",
       "9308  This is a great app but I didn't get my neckla...      3              1   \n",
       "9309  11-3-22- I have 107 S&S items. It is impossibl...      4              9   \n",
       "9310  App sucks! Glitchy, slow, hurts my eyes cuz im...      3              0   \n",
       "9311  Look this app was good at one point in time bu...      1              0   \n",
       "\n",
       "     reviewCreatedVersion                   at  replyContent  repliedAt  \\\n",
       "0             26.23.4.100  2023-12-28 21:20:56           NaN        NaN   \n",
       "1             26.19.2.100  2023-10-02 12:09:02           NaN        NaN   \n",
       "2             26.20.0.100  2023-10-25 03:46:34           NaN        NaN   \n",
       "3                     NaN  2023-11-12 01:54:20           NaN        NaN   \n",
       "4             24.22.0.100  2023-01-10 09:30:07           NaN        NaN   \n",
       "...                   ...                  ...           ...        ...   \n",
       "9307          26.21.0.100  2023-11-03 01:06:14           NaN        NaN   \n",
       "9308          22.14.0.100  2022-06-01 13:35:57           NaN        NaN   \n",
       "9309          24.20.2.100  2022-11-03 11:59:23           NaN        NaN   \n",
       "9310          24.12.6.100  2022-07-21 14:35:03           NaN        NaN   \n",
       "9311          26.22.0.100  2023-12-07 13:47:06           NaN        NaN   \n",
       "\n",
       "       appVersion  sentiment  lengthContent Language  \n",
       "0     26.23.4.100          0            224       en  \n",
       "1     26.19.2.100          2             32       en  \n",
       "2     26.20.0.100          2             34       en  \n",
       "3             NaN          2            111       en  \n",
       "4     24.22.0.100          2             64       en  \n",
       "...           ...        ...            ...      ...  \n",
       "9307  26.21.0.100          2             42       en  \n",
       "9308  22.14.0.100          1            240       en  \n",
       "9309  24.20.2.100          2            320       en  \n",
       "9310  24.12.6.100          1            231       en  \n",
       "9311  26.22.0.100          0            380       en  \n",
       "\n",
       "[9312 rows x 15 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "df424c22-acdb-4be4-a76c-9d8076a3e620",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9312, 15)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b172604f-6ff9-4290-8b5a-8a1e8243ceae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentiment\n",
      "0    3104\n",
      "1    3104\n",
      "2    3104\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "sentiment_counts_balanced = dataset['sentiment'].value_counts().sort_index()\n",
    "print(sentiment_counts_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "07ea3b62-9eed-4a02-a4ce-12ebc1bc66d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained BERT model and tokenizer\n",
    "#model_name = \"/home/patrick.araujo/llama2/llama/llama-2-7b-hf\"\n",
    "#model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "model_name = \"bert-base-uncased\"\n",
    "#model_name = \"google-t5/t5-base\"\n",
    "#model_name = \"google-t5/t5-small\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3, token=access_token)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "df3313b1-73fa-4368-ab30-14c1a6c22621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and validation datasets\n",
    "comments = dataset[['content', 'sentiment']]\n",
    "train_data, val_data = train_test_split(comments, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5cfbd6b8-e097-4751-8784-6274a056dec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>Usually love the app but lately if I try to us...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5813</th>\n",
       "      <td>It's okay sometimes if you really follow the s...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Here's to all the people that make all the goo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1345</th>\n",
       "      <td>It's amazing but some of the stuff I want isn'...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5057</th>\n",
       "      <td>How disgraceful all these complaints and still...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>No longer works with Tablets mine is a Samsung...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>Just wish we had more American Made products t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>Excellent customer service. So many choices! B...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>Amazon prices aren't bad, they deliver fairly ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>Lowered stars for embedded autoplay videos</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7449 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  sentiment\n",
       "503   Usually love the app but lately if I try to us...          1\n",
       "5813  It's okay sometimes if you really follow the s...          2\n",
       "274   Here's to all the people that make all the goo...          2\n",
       "1345  It's amazing but some of the stuff I want isn'...          2\n",
       "5057  How disgraceful all these complaints and still...          0\n",
       "...                                                 ...        ...\n",
       "5734  No longer works with Tablets mine is a Samsung...          0\n",
       "5191  Just wish we had more American Made products t...          2\n",
       "5390  Excellent customer service. So many choices! B...          2\n",
       "860   Amazon prices aren't bad, they deliver fairly ...          2\n",
       "7270         Lowered stars for embedded autoplay videos          0\n",
       "\n",
       "[7449 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3acf7ad1-8069-4018-8f34-a3f3fec5ccb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8638</th>\n",
       "      <td>Amazon shopping app doesn't allow user to clea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Can't vote my orders. It just refreshes my ord...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>App is barely better than web experience, but ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4401</th>\n",
       "      <td>Wishlist scrolling doesn't work</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3095</th>\n",
       "      <td>With the problems of item deliveries thru USPS...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6657</th>\n",
       "      <td>Have to watch an add before you can use the ap...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4271</th>\n",
       "      <td>App is not bad, but I used it mostly to track ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>I dispise that the app has injected a search i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603</th>\n",
       "      <td>I've officially deleted my account after using...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2362</th>\n",
       "      <td>Video ads chopping scrolling, this is no a fre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1863 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  sentiment\n",
       "8638  Amazon shopping app doesn't allow user to clea...          1\n",
       "131   Can't vote my orders. It just refreshes my ord...          1\n",
       "3509  App is barely better than web experience, but ...          2\n",
       "4401                    Wishlist scrolling doesn't work          0\n",
       "3095  With the problems of item deliveries thru USPS...          0\n",
       "...                                                 ...        ...\n",
       "6657  Have to watch an add before you can use the ap...          0\n",
       "4271  App is not bad, but I used it mostly to track ...          1\n",
       "2404  I dispise that the app has injected a search i...          0\n",
       "6603  I've officially deleted my account after using...          0\n",
       "2362  Video ads chopping scrolling, this is no a fre...          0\n",
       "\n",
       "[1863 rows x 2 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71112062-c337-4f89-9051-6cead7c18968",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.pad_token = tokenizer.eos_token\n",
    "#tokenizer.padding_size = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe64e1df-52ac-4c1a-b9f5-d76719dc5715",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 512\n",
    "\n",
    "def tokenizerFunction(string):\n",
    "  # Tokenize a list of texts and return a dictionary with the tokenization outputs\n",
    "  tokens = tokenizer(string, padding='max_length', truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
    "  return tokens\n",
    "\n",
    "train_encodings = train_data['content'].apply(tokenizerFunction)\n",
    "val_encodings = val_data['content'].apply(tokenizerFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "944bcbb4-7b27-4e7c-b90a-e4a3a782e86f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "503     [input_ids, token_type_ids, attention_mask]\n",
       "5813    [input_ids, token_type_ids, attention_mask]\n",
       "274     [input_ids, token_type_ids, attention_mask]\n",
       "1345    [input_ids, token_type_ids, attention_mask]\n",
       "5057    [input_ids, token_type_ids, attention_mask]\n",
       "                           ...                     \n",
       "5734    [input_ids, token_type_ids, attention_mask]\n",
       "5191    [input_ids, token_type_ids, attention_mask]\n",
       "5390    [input_ids, token_type_ids, attention_mask]\n",
       "860     [input_ids, token_type_ids, attention_mask]\n",
       "7270    [input_ids, token_type_ids, attention_mask]\n",
       "Name: content, Length: 7449, dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1cd74a5-2bfa-4be2-acdb-b83beb812090",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8638    [input_ids, token_type_ids, attention_mask]\n",
       "131     [input_ids, token_type_ids, attention_mask]\n",
       "3509    [input_ids, token_type_ids, attention_mask]\n",
       "4401    [input_ids, token_type_ids, attention_mask]\n",
       "3095    [input_ids, token_type_ids, attention_mask]\n",
       "                           ...                     \n",
       "6657    [input_ids, token_type_ids, attention_mask]\n",
       "4271    [input_ids, token_type_ids, attention_mask]\n",
       "2404    [input_ids, token_type_ids, attention_mask]\n",
       "6603    [input_ids, token_type_ids, attention_mask]\n",
       "2362    [input_ids, token_type_ids, attention_mask]\n",
       "Name: content, Length: 1863, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e7d205e7-4dbb-407d-a420-d0da2669d651",
   "metadata": {},
   "outputs": [],
   "source": [
    "def creatingDataframe(encodings):\n",
    "  indices = encodings.index.to_numpy()\n",
    "\n",
    "  df = pd.DataFrame(columns=['input_ids', 'attention_mask'])\n",
    "  \n",
    "  # Assuming 'content' is a Series or List containing tuples/lists\n",
    "  for element in encodings:\n",
    "    input_ids = element['input_ids'][0].numpy()              # Replace with correct index based on your data structure\n",
    "    attention_mask = element['attention_mask'][0].numpy()    # Replace with correct index\n",
    "    df.loc[len(df.index)] = [input_ids, attention_mask]\n",
    "  df_index = pd.DataFrame(indices, columns=['index'])\n",
    "  df['index'] = df_index['index']\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c2e7717f-ff65-43b7-b043-6bc2fe2f7dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "# Convert labels to tensors\n",
    "train_dataset = creatingDataframe(train_encodings)\n",
    "train_labels = train_data['sentiment'].reset_index(name='label')\n",
    "train_dataset = pd.merge(train_dataset, train_labels, on='index')\n",
    "\n",
    "val_dataset = creatingDataframe(val_encodings)\n",
    "val_labels = val_data['sentiment'].reset_index(name='label')\n",
    "val_dataset = pd.merge(val_dataset, val_labels, on='index')\n",
    "\n",
    "# Define batch size and create data loaders\n",
    "batch_size = 8  # Adjust as needed\n",
    "# train_dataset = SentimentDataset(train_encodings, train_labels)\n",
    "# val_dataset = SentimentDataset(val_encodings, val_labels)\n",
    "#train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=default_data_collator)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=default_data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6cd9e793-baa7-4690-9006-3adf4d90aa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.drop('index', axis=1)\n",
    "val_dataset = val_dataset.drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "92a84512-7e3e-4982-a700-5529b1721b6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 2788, 2293, 1996, 10439, 2021, 9906, 206...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 2009, 1005, 1055, 3100, 2823, 2065, 2017...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 2182, 1005, 1055, 2000, 2035, 1996, 2111...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 2009, 1005, 1055, 6429, 2021, 2070, 1997...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 2129, 29591, 3993, 2035, 2122, 10821, 19...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7444</th>\n",
       "      <td>[101, 2053, 2936, 2573, 2007, 17596, 3067, 200...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7445</th>\n",
       "      <td>[101, 2074, 4299, 2057, 2018, 2062, 2137, 2081...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7446</th>\n",
       "      <td>[101, 6581, 8013, 2326, 1012, 2061, 2116, 9804...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7447</th>\n",
       "      <td>[101, 9733, 7597, 4995, 1005, 1056, 2919, 1010...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7448</th>\n",
       "      <td>[101, 6668, 3340, 2005, 11157, 8285, 13068, 68...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7449 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_ids  \\\n",
       "0     [101, 2788, 2293, 1996, 10439, 2021, 9906, 206...   \n",
       "1     [101, 2009, 1005, 1055, 3100, 2823, 2065, 2017...   \n",
       "2     [101, 2182, 1005, 1055, 2000, 2035, 1996, 2111...   \n",
       "3     [101, 2009, 1005, 1055, 6429, 2021, 2070, 1997...   \n",
       "4     [101, 2129, 29591, 3993, 2035, 2122, 10821, 19...   \n",
       "...                                                 ...   \n",
       "7444  [101, 2053, 2936, 2573, 2007, 17596, 3067, 200...   \n",
       "7445  [101, 2074, 4299, 2057, 2018, 2062, 2137, 2081...   \n",
       "7446  [101, 6581, 8013, 2326, 1012, 2061, 2116, 9804...   \n",
       "7447  [101, 9733, 7597, 4995, 1005, 1056, 2919, 1010...   \n",
       "7448  [101, 6668, 3340, 2005, 11157, 8285, 13068, 68...   \n",
       "\n",
       "                                         attention_mask  label  \n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      1  \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...      2  \n",
       "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      2  \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      2  \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \n",
       "...                                                 ...    ...  \n",
       "7444  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \n",
       "7445  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, ...      2  \n",
       "7446  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      2  \n",
       "7447  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      2  \n",
       "7448  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...      0  \n",
       "\n",
       "[7449 rows x 3 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d8c29660-3d7f-42c6-ab1d-d4244488c235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[101, 9733, 6023, 10439, 2987, 1005, 1056, 349...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[101, 2064, 1005, 1056, 3789, 2026, 4449, 1012...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[101, 10439, 2003, 4510, 2488, 2084, 4773, 332...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[101, 4299, 9863, 28903, 2987, 1005, 1056, 214...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[101, 2007, 1996, 3471, 1997, 8875, 23534, 270...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1858</th>\n",
       "      <td>[101, 2031, 2000, 3422, 2019, 5587, 2077, 2017...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1859</th>\n",
       "      <td>[101, 10439, 2003, 2025, 2919, 1010, 2021, 104...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>[101, 1045, 4487, 13102, 5562, 2008, 1996, 104...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1861</th>\n",
       "      <td>[101, 1045, 1005, 2310, 3985, 17159, 2026, 407...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862</th>\n",
       "      <td>[101, 2678, 14997, 24494, 4691, 28903, 1010, 2...</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1863 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              input_ids  \\\n",
       "0     [101, 9733, 6023, 10439, 2987, 1005, 1056, 349...   \n",
       "1     [101, 2064, 1005, 1056, 3789, 2026, 4449, 1012...   \n",
       "2     [101, 10439, 2003, 4510, 2488, 2084, 4773, 332...   \n",
       "3     [101, 4299, 9863, 28903, 2987, 1005, 1056, 214...   \n",
       "4     [101, 2007, 1996, 3471, 1997, 8875, 23534, 270...   \n",
       "...                                                 ...   \n",
       "1858  [101, 2031, 2000, 3422, 2019, 5587, 2077, 2017...   \n",
       "1859  [101, 10439, 2003, 2025, 2919, 1010, 2021, 104...   \n",
       "1860  [101, 1045, 4487, 13102, 5562, 2008, 1996, 104...   \n",
       "1861  [101, 1045, 1005, 2310, 3985, 17159, 2026, 407...   \n",
       "1862  [101, 2678, 14997, 24494, 4691, 28903, 1010, 2...   \n",
       "\n",
       "                                         attention_mask  label  \n",
       "0     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      1  \n",
       "1     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      1  \n",
       "2     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      2  \n",
       "3     [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...      0  \n",
       "4     [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \n",
       "...                                                 ...    ...  \n",
       "1858  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \n",
       "1859  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      1  \n",
       "1860  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \n",
       "1861  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \n",
       "1862  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...      0  \n",
       "\n",
       "[1863 rows x 3 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09d2e179-4e31-4546-b72a-d1872aa88932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class\n",
    "#class CustomDataset(Dataset):\n",
    "#    def __init__(self, dataframe, data):\n",
    "#        self._data = data\n",
    "#\n",
    "#    def __len__(self):\n",
    "#        return len(self._data)\n",
    "#\n",
    "#    def __getitem__(self, idx):\n",
    "#        label = self.labels[idx]\n",
    "#        input_ids = self.input_ids[idx]\n",
    "#        attention_mask = self.attention_masks[idx]\n",
    "#        return {\n",
    "#            'input_ids': torch.tensor(dataframe['input_ids'], dtype=torch.long),\n",
    "#            'attention_mask': torch.tensor(dataframe['attention_mask'], dtype=torch.long),\n",
    "#            'labels': torch.tensor(dataframe['label'], dtype=torch.long)\n",
    "#        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fca67fd7-4642-4338-9dd7-db54be5ca07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset = CustomDataset(train_dataset, train_data)\n",
    "#val_dataset = CustomDataset(val_dataset, val_data)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_dataset)\n",
    "val_dataset = Dataset.from_pandas(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29e8dc7f-ef52-4b71-827a-20de4a4f4d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments with early stopping\n",
    "training_args = TrainingArguments(\n",
    "    # Positional arguments:\n",
    "    output_dir=\"./bert-base-uncased_sentiment_model_steps\",\n",
    "    logging_dir=\"./logs_b_steps\",\n",
    "\n",
    "    # Keyword arguments:\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,                         # Adjust as needed\n",
    "    save_total_limit=2,                     # Adjust as needed. Only last 2 models are saved. Older ones are deleted.\n",
    "    num_train_epochs=3,                     # Adjust as needed\n",
    "    save_steps=500,                         # Adjust as needed\n",
    "    metric_for_best_model=\"eval_loss\",      # Use validation loss for early stopping\n",
    "    save_strategy=\"steps\",\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c691f66c-98b8-4d40-b5a4-79fea7ffde85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # Convert logits to predicted labels\n",
    "    predicted_labels = np.argmax(logits, axis=1)\n",
    "\n",
    "    metrics = {}\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels, predicted_labels)\n",
    "    metrics['accuracy'] = accuracy\n",
    "\n",
    "    # Calculate precision, recall, F1 score, and support for each class\n",
    "    precision, recall, f1, support = precision_recall_fscore_support(labels, predicted_labels)    \n",
    "    \n",
    "\n",
    "    # Create a dictionary to store metrics for each class\n",
    "    class_metrics = {}\n",
    "    for i in range(len(precision)):\n",
    "        class_metrics[f'class_{i}'] = {\n",
    "            'precision': precision[i],\n",
    "            'recall': recall[i],\n",
    "            'f1': f1[i],\n",
    "            'support': support[i]\n",
    "        }\n",
    "\n",
    "    precision_ALL = precision_score(labels, predicted_labels, average='macro')\n",
    "    recall_ALL = recall_score(labels, predicted_labels, average='macro')\n",
    "    f1_ALL = f1_score(labels, predicted_labels, average='macro')\n",
    "\n",
    "    metrics['precision'] = precision_ALL\n",
    "    metrics['recall'] = recall_ALL\n",
    "    metrics['f1'] = f1_ALL\n",
    "    \n",
    "    # Print and return the metrics\n",
    "    for class_name, c_metrics in class_metrics.items():\n",
    "        metrics[f'{class_name}_precision'] = c_metrics[\"precision\"]\n",
    "        metrics[f'{class_name}_recall'] = c_metrics[\"recall\"]\n",
    "        metrics[f'{class_name}_f1'] = c_metrics[\"f1\"]\n",
    "        metrics[f'{class_name}_support'] = c_metrics[\"support\"]\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f1b545c-548c-475a-8f34-704c9e9e2a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Detected kernel version 5.4.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=default_data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bc10a088-c846-4be0-86b4-089b2cb98a61",
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "Caught OutOfMemoryError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n    output = module(*input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py\", line 1564, in forward\n    outputs = self.bert(\n              ^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py\", line 1013, in forward\n    encoder_outputs = self.encoder(\n                      ^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py\", line 607, in forward\n    layer_outputs = layer_module(\n                    ^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py\", line 497, in forward\n    self_attention_outputs = self.attention(\n                             ^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py\", line 427, in forward\n    self_outputs = self.self(\n                   ^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py\", line 325, in forward\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 52.38 MiB is free. Process 1983499 has 44.11 GiB memory in use. Including non-PyTorch memory, this process has 3.29 GiB memory in use. Of the allocated memory 2.95 GiB is allocated by PyTorch, and 18.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[52], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Fine-tune the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1544\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/trainer.py:1869\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1869\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1872\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1873\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1875\u001b[0m ):\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1877\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/trainer.py:2772\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2772\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2775\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/trainer.py:2795\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2794\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2795\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2796\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2797\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:185\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule(\u001b[38;5;241m*\u001b[39minputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    184\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[0;32m--> 185\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgather(outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/parallel/data_parallel.py:200\u001b[0m, in \u001b[0;36mDataParallel.parallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, replicas: Sequence[T], inputs: Sequence[Any], kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[Any]:\n\u001b[0;32m--> 200\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparallel_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_ids\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mreplicas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py:108\u001b[0m, in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m    106\u001b[0m     output \u001b[38;5;241m=\u001b[39m results[i]\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, ExceptionWrapper):\n\u001b[0;32m--> 108\u001b[0m         \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/torch/_utils.py:722\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: Caught OutOfMemoryError in replica 1 on device 1.\nOriginal Traceback (most recent call last):\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/parallel/parallel_apply.py\", line 83, in _worker\n    output = module(*input, **kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py\", line 1564, in forward\n    outputs = self.bert(\n              ^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py\", line 1013, in forward\n    encoder_outputs = self.encoder(\n                      ^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py\", line 607, in forward\n    layer_outputs = layer_module(\n                    ^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py\", line 497, in forward\n    self_attention_outputs = self.attention(\n                             ^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py\", line 427, in forward\n    self_outputs = self.self(\n                   ^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1511, in _wrapped_call_impl\n    return self._call_impl(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1520, in _call_impl\n    return forward_call(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py\", line 325, in forward\n    attention_scores = torch.matmul(query_layer, key_layer.transpose(-1, -2))\n                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\ntorch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 96.00 MiB. GPU 1 has a total capacity of 47.45 GiB of which 52.38 MiB is free. Process 1983499 has 44.11 GiB memory in use. Including non-PyTorch memory, this process has 3.29 GiB memory in use. Of the allocated memory 2.95 GiB is allocated by PyTorch, and 18.34 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2d7a2c-40aa-4f64-ac59-930d1b95b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "results = trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab891145-62c8-4f14-9f0b-541b0135fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd8cc3d-1be5-4c4b-b35f-acf46e95d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save_pretrained(\"./bert-base-uncased_sentiment_model_steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b575ece3-3c16-4843-be04-6583e1e4937c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
