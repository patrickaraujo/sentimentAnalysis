{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b39fd-5115-497f-b6a5-835eb11b27ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a04bc24-b2ba-43e0-b3c6-dbe01ca11ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick.araujo/miniconda3/envs/llama/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Unable to import required dependencies:\nnumpy: No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, recall_score, precision_score, f1_score \u001b[38;5;66;03m# Import all needed metrics\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/llama/lib/python3.12/site-packages/pandas/__init__.py:19\u001b[0m\n\u001b[1;32m     16\u001b[0m         _missing_dependencies\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_dependency\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_e\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _missing_dependencies:  \u001b[38;5;66;03m# pragma: no cover\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[1;32m     20\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to import required dependencies:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(_missing_dependencies)\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Unable to import required dependencies:\nnumpy: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score # Import all needed metrics\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, EarlyStoppingCallback, default_data_collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd86b2cb-2061-43b6-930b-91ace234502c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48425f0-c448-4508-a9df-1d5807927bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained BERT model and tokenizer\n",
    "#model_name = \"mistralai/Mistral-7B-v0.1\"\n",
    "model_name = \"/home/patrick.araujo/llama2/llama/llama-2-7b-hf\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=3, token=access_token)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "919c0100-c291-4924-a42d-636e00ef45a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_size = 'right'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02589128-27b2-4846-ab10-08c578e86a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/home/patrick.araujo/llama2/datasets/balanced_output_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2569654c-6d26-4989-88db-aca584be4008",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8849551b-c4ea-4987-82e7-916abf92b198",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7be18e-fb8c-48e1-bc73-4abd96786180",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train and validation datasets\n",
    "comments = dataset[['content', 'sentiment']]\n",
    "train_data, val_data = train_test_split(comments, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9431269-9180-422a-aabe-ef3ec4be9861",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tokenizerFunction(string):\n",
    "    tokens = tokenizer(string, padding=True, truncation=True)\n",
    "    return tokens\n",
    "\n",
    "train_encodings = train_data['content'].apply(tokenizerFunction)\n",
    "val_encodings = val_data['content'].apply(tokenizerFunction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826093d8-e00c-46c4-a56b-c4b054f42341",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466e14de-a76f-4f1d-b0ac-2d6ce1ec72aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d52a6f-12dc-4075-a76f-0d58443119dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentimentDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long) # Ensure labels are of type long\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4b4535-33c3-4cc7-a0f0-5f2834e1bbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_labels = train_data['sentiment'].tolist()\n",
    "val_labels = val_data['sentiment'].tolist()\n",
    "\n",
    "train_dataset = SentimentDataset(train_encodings, train_labels)\n",
    "val_dataset = SentimentDataset(val_encodings, val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f17ebc-2b12-46af-a559-be3e8bf53487",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments with early stopping\n",
    "training_args = TrainingArguments(\n",
    "    # Positional arguments:\n",
    "    output_dir=\"./llama2_sentiment_model\",\n",
    "    logging_dir=\"./logs\",\n",
    "\n",
    "    # Keyword arguments:\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_total_limit=2,\n",
    "    num_train_epochs=3,\n",
    "    save_steps=500,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c00e4505-1b82-4677-af87-544f932d4b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "  pred, labels = p\n",
    "  pred = np.argmax(pred, axis=1)\n",
    "  accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "  recall = recall_score(y_true=labels, y_pred=pred, average='macro')\n",
    "  precision = precision_score(y_true=labels, y_pred=pred, average='macro')\n",
    "  f1 = f1_score(y_true=labels, y_pred=pred, average='macro')  # Add line for F1 score\n",
    "  return  {\n",
    "            'accuracy': accuracy,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1  # Include F1 score in the dictionary\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93781a2b-84e4-4775-aab5-e2afe5f04df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=default_data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3b90c7-dc1c-4798-8e9d-47abfdbfe1bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a053bea-44e0-4892-8870-ec91d8068c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = train_data['sentiment'labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad4cca3-68a4-4734-9dfd-1da496d67951",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf5cae8-c030-4ea0-8011-6d44cbb4461f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct approach to combine the data\n",
    "combined_data = []\n",
    "for (index, (input_ids, attention_mask)), label in zip(train_df.items(), x):\n",
    "    combined_data.append([input_ids, attention_mask, label])\n",
    "\n",
    "# Convert combined_data to a pandas Series or DataFrame as needed\n",
    "combined_series = pd.Series(combined_data, index=train_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62bfe15-c1d1-4075-a19b-70ce094c6bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming your Series is named `df`\n",
    "def add_label(row):\n",
    "    # Define the logic for calculating the label based on your specific needs\n",
    "    # For example, if you have separate label data:\n",
    "    label = your_label_data[row.name]\n",
    "    return [row[0], row[1], label]\n",
    "\n",
    "df = train_df.apply(add_label, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4d67f9-fb3e-44dc-b741-8bb786792f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize train and validation data\n",
    "train_tokens = tokenizer(train_data['content']), padding=True, truncation=True)\n",
    "val_tokens = tokenizer(str(val_data['content']), padding=True, truncation=True)\n",
    "\n",
    "# Access tokenized text and other attributes\n",
    "train_text = train_tokens['input_ids']\n",
    "train_attention_mask = train_tokens['attention_mask']\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "train_df = pd.DataFrame(inputID_attentionMask(train_text, train_attention_mask))\n",
    "train_df['labels'] = train_data['sentiment']\n",
    "print(train_df)\n",
    "# Do the same for validation data\n",
    "val_text = val_tokens['input_ids']\n",
    "val_attention_mask = val_tokens['attention_mask']\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c331e17f-666d-41dc-a621-bb65d09c00cc",
   "metadata": {},
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d6c0d0-f000-4e6f-ad16-d57e09a05814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size and create data loaders\n",
    "batch_size = 8  # Adjust as needed\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=default_data_collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=default_data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30957672-303e-4c75-b402-cbaf3c3a9546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments with early stopping\n",
    "training_args = TrainingArguments(\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    output_dir=\"./llama2_model\",\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,  # Adjust as needed\n",
    "    save_total_limit=2,  # Adjust as needed. Only last 2 models are saved. Older ones are deleted.\n",
    "    num_train_epochs=3,  # Adjust as needed\n",
    "    save_steps=500,  # Adjust as needed\n",
    "    logging_dir=\"./logs\",\n",
    "    metric_for_best_model=\"eval_loss\",  # Use validation loss for early stopping\n",
    "    load_best_model_at_end=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be97fed-4a88-47eb-92dd-e562ff9d6e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(p):\n",
    "  pred, labels = p\n",
    "  pred = np.argmax(pred, axis=1)\n",
    "  accuracy = accuracy_score(y_true=labels, y_pred=pred)\n",
    "  recall = recall_score(y_true=labels, y_pred=pred, average='macro')\n",
    "  precision = precision_score(y_true=labels, y_pred=pred, average='macro')\n",
    "  f1 = f1_score(y_true=labels, y_pred=pred, average='macro')  # Add line for F1 score\n",
    "  return  {Z\n",
    "            'accuracy': accuracy,\n",
    "            'recall': recall,\n",
    "            'precision': precision,\n",
    "            'f1': f1  # Include F1 score in the dictionary\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd742df9-54be-4787-8ba6-9b08013264f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=default_data_collator,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks = [EarlyStoppingCallback(early_stopping_patience=3)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5f4c94-1506-47e0-a22f-65c330237dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b2341b-a0cd-4ee0-8e06-0df4f9352c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "peft_config = LoraConfig(\n",
    "        lora_alpha=16, \n",
    "        lora_dropout=0.1,\n",
    "        r=64,\n",
    "        bias=\"none\",\n",
    "        target_modules=\"all-linear\",\n",
    "        task_type=TaskType.SEQ_CLS,\n",
    ")\n",
    "\n",
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"logs\",                        # directory to save and repository id\n",
    "    num_train_epochs=3,                       # number of training epochs\n",
    "    per_device_train_batch_size=1,            # batch size per device during training\n",
    "    gradient_accumulation_steps=8,            # number of steps before performing a backward/update pass\n",
    "    gradient_checkpointing=True,              # use gradient checkpointing to save memory\n",
    "    optim=\"paged_adamw_32bit\",\n",
    "    save_steps=0,\n",
    "    logging_steps=25,                         # log every 10 steps\n",
    "    learning_rate=2e-4,                       # learning rate, based on QLoRA paper\n",
    "    weight_decay=0.001,\n",
    "    fp16=True,\n",
    "    bf16=False,\n",
    "    max_grad_norm=0.3,                        # max gradient norm based on QLoRA paper\n",
    "    max_steps=-1,\n",
    "    warmup_ratio=0.03,                        # warmup ratio based on QLoRA paper\n",
    "    group_by_length=True,\n",
    "    lr_scheduler_type=\"cosine\",               # use cosine learning rate scheduler\n",
    "    report_to=\"tensorboard\",                  # report metrics to tensorboard\n",
    "    evaluation_strategy=\"epoch\"               # save checkpoint every epoch\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    peft_config=peft_config,\n",
    "    dataset_text_field=\"text\",\n",
    "    tokenizer=tokenizer,\n",
    "    max_seq_length=1024,\n",
    "    packing=False,\n",
    "    dataset_kwargs={\n",
    "        \"add_special_tokens\": False,\n",
    "        \"append_concat_token\": False,\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama",
   "language": "python",
   "name": "llama"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
